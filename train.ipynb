{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a4c2f3",
   "metadata": {},
   "source": [
    "### train에 대해서 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2de6ad5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22252\\2498871337.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load('tensor/train.pt')\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22252\\2498871337.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_data   = torch.load('tensor/val.pt')\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22252\\2498871337.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load('tensor/test.pt')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from cascademodel3 import CascadeCVAE\n",
    "\n",
    "train_data = torch.load('tensor/train.pt')\n",
    "val_data   = torch.load('tensor/val.pt')\n",
    "test_data = torch.load('tensor/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfff3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mt = train_data['mt']\n",
    "train_sp = train_data['sp']\n",
    "train_pt = train_data['pt']\n",
    "train_op   = train_data['op']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab91d0",
   "metadata": {},
   "source": [
    "### val에 대해서 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41539835",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mt = val_data['mt']\n",
    "val_sp = val_data['sp']\n",
    "val_pt = val_data['pt']\n",
    "val_op   = val_data['op']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b2f63",
   "metadata": {},
   "source": [
    "### test에 대해서 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ada4af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mt = test_data['mt']\n",
    "test_sp = test_data['sp']\n",
    "test_pt = test_data['pt']\n",
    "test_op   = test_data['op']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72db0155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. 데이터 차원 정의 (데이터에 맞게 수정 필요)\n",
    "# train.ipynb의 출력 예시([1182, 23])를 참고하여 설정하세요.\n",
    "metal_dim      = train_mt.shape[1]\n",
    "supporting_dim = train_sp.shape[1]\n",
    "pretreat_dim   = train_pt.shape[1]\n",
    "operating_dim  = train_op.shape[1]\n",
    "\n",
    "# 3. 모델 및 옵티마이저 생성\n",
    "model = CascadeCVAE(\n",
    "    metal_dim=metal_dim, \n",
    "    supporting_dim=supporting_dim, \n",
    "    pretreat_dim=pretreat_dim, \n",
    "    operating_dim=operating_dim,\n",
    "    z_dim=16\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b57ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500] | Train Loss: 0.2041 | Val Loss: 0.1294\n",
      "Epoch [20/500] | Train Loss: 0.1882 | Val Loss: 0.1159\n",
      "Epoch [30/500] | Train Loss: 0.1710 | Val Loss: 0.1043\n",
      "Epoch [40/500] | Train Loss: 0.1622 | Val Loss: 0.1005\n",
      "Epoch [50/500] | Train Loss: 0.1563 | Val Loss: 0.0963\n",
      "Epoch [60/500] | Train Loss: 0.1527 | Val Loss: 0.0923\n",
      "Epoch [70/500] | Train Loss: 0.1489 | Val Loss: 0.0907\n",
      "Epoch [80/500] | Train Loss: 0.1452 | Val Loss: 0.0906\n",
      "Epoch [90/500] | Train Loss: 0.1432 | Val Loss: 0.0869\n",
      "Epoch [100/500] | Train Loss: 0.1404 | Val Loss: 0.0863\n",
      "Epoch [110/500] | Train Loss: 0.1382 | Val Loss: 0.0841\n",
      "Epoch [120/500] | Train Loss: 0.1362 | Val Loss: 0.0835\n",
      "Epoch [130/500] | Train Loss: 0.1343 | Val Loss: 0.0824\n",
      "Epoch [140/500] | Train Loss: 0.1319 | Val Loss: 0.0804\n",
      "Epoch [150/500] | Train Loss: 0.1292 | Val Loss: 0.0799\n",
      "Epoch [160/500] | Train Loss: 0.1279 | Val Loss: 0.0800\n",
      "Epoch [170/500] | Train Loss: 0.1251 | Val Loss: 0.0765\n",
      "Epoch [180/500] | Train Loss: 0.1245 | Val Loss: 0.0794\n",
      "Epoch [190/500] | Train Loss: 0.1218 | Val Loss: 0.0748\n",
      "Epoch [200/500] | Train Loss: 0.1200 | Val Loss: 0.0721\n",
      "Epoch [210/500] | Train Loss: 0.1193 | Val Loss: 0.0718\n",
      "Epoch [220/500] | Train Loss: 0.1162 | Val Loss: 0.0710\n",
      "Epoch [230/500] | Train Loss: 0.1155 | Val Loss: 0.0726\n",
      "Epoch [240/500] | Train Loss: 0.1146 | Val Loss: 0.0687\n",
      "Epoch [250/500] | Train Loss: 0.1122 | Val Loss: 0.0681\n",
      "Epoch [260/500] | Train Loss: 0.1120 | Val Loss: 0.0694\n",
      "Epoch [270/500] | Train Loss: 0.1111 | Val Loss: 0.0694\n",
      "Epoch [280/500] | Train Loss: 0.1084 | Val Loss: 0.0656\n",
      "Epoch [290/500] | Train Loss: 0.1074 | Val Loss: 0.0655\n",
      "Epoch [300/500] | Train Loss: 0.1062 | Val Loss: 0.0646\n",
      "Epoch [310/500] | Train Loss: 0.1058 | Val Loss: 0.0647\n",
      "Epoch [320/500] | Train Loss: 0.1044 | Val Loss: 0.0645\n",
      "Epoch [330/500] | Train Loss: 0.1024 | Val Loss: 0.0639\n",
      "Epoch [340/500] | Train Loss: 0.1040 | Val Loss: 0.0623\n",
      "Epoch [350/500] | Train Loss: 0.1016 | Val Loss: 0.0615\n",
      "Epoch [360/500] | Train Loss: 0.0999 | Val Loss: 0.0625\n",
      "Epoch [370/500] | Train Loss: 0.0992 | Val Loss: 0.0625\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # --- TRAIN PHASE ---\n",
    "    model.train()\n",
    "    train_total_loss = 0.0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        # 데이터 분리 및 GPU 이동\n",
    "        mt, sp, pt, op = [d.to(device) for d in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        out = model(mt, sp, pt, op)\n",
    "        \n",
    "        # Loss 계산 (Stage 1의 7번 인덱스 강조 포함)\n",
    "        loss, _ = model.compute_loss_all_loss3(\n",
    "            out, mt, sp, pt,\n",
    "            beta=1.0, \n",
    "            metal_focus_idx=7, \n",
    "            metal_focus_weight=2.0 # 강조를 위해 가중치 조절 가능\n",
    "        )\n",
    "        \n",
    "        # Backward & Update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = train_total_loss / len(train_loader)\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "    # --- VALIDATION PHASE ---\n",
    "    model.eval()\n",
    "    val_total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            mt, sp, pt, op = [d.to(device) for d in batch]\n",
    "            out = model(mt, sp, pt, op)\n",
    "            loss, _ = model.compute_loss_all_loss3(out, mt, sp, pt)\n",
    "            val_total_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_total_loss / len(val_loader)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "    # 10 Epoch마다 진행 상황 출력\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
